version = 1

[*]
jinja = on
flash-attn = on
fit = on
n-gpu-layers = 99

[ggml-org/gpt-oss-120b-GGUF]
ctx-size = 128000
temp = 1.0
min-p = 0.0
top-p = 1.0
top-k = 0.0
chat-template-kwargs = {"reasoning_effort": "medium"}

[unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF]
hf = unsloth/Qwen3-Coder-30B-A3B-Instruct-GGUF:UD-Q8_K_XL
ctx-size = 128000
temp = 0.7
min-p = 0.0
top-p = 0.80
top-k = 20
repeat-penalty = 1.05

[unsloth/Qwen3-Next-80B-A3B-Instruct-GGUF]
hf = unsloth/Qwen3-Next-80B-A3B-Instruct-GGUF:UD-Q6_K_XL
ctx-size = 128000
temp = 0.7
min-p = 0.00
top-p = 0.80
top-k = 20
repeat-penalty = 1.05

[unsloth/Qwen3-Next-80B-A3B-Thinking-GGUF]
hf = unsloth/Qwen3-Next-80B-A3B-Thinking-GGUF:UD-Q6_K_XL
ctx-size = 128000
temp = 0.7
min-p = 0.00
top-p = 0.80
top-k = 20
repeat-penalty = 1.05

[unsloth/GLM-4.7-Flash-GGUF]
hf = unsloth/GLM-4.7-Flash-GGUF:UD-Q8_K_XL
ctx-size = 202752
flash-attn = off
temp = 0.7
top-p = 1.0
min-p = 0.01

[unsloth/Nemotron-3-Nano-30B-A3B-GGUF]
hf = unsloth/Nemotron-3-Nano-30B-A3B-GGUF:UD-Q8_K_XL
ctx-size = 128000
temp = 0.6
top-p = 0.95
